1. data collection
2. feature engineering; select the features
3. split data
4. model selection and train data 
5. model eval and optim
6. deplou
7. ci/cd

Train, Test, Validate 

train -> build model 

Logistic regression: binary classifier supervised output can be numerical or categorical; linear model  too simple
decision tree: works as tree, end nodes: predicted values overfit
random forest: combines prediction of multiple decision trees -> becomes robust, accurate   too expensive 

overfitting good training but poor testing

underfitting; poor training as the data is too simple so it has high bias and low variance 
insufficient feature engineering; the 

